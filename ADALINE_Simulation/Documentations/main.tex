\documentclass{article}
\usepackage[fleqn]{amsmath}
\usepackage{graphicx}
\graphicspath{{Images/}}
\begin{document}
	\noindent Name : Febrian Nugroho\\
	NIM :2301930551
	\begin{center}
		\Large Answer of Assignment II\\
		\Large Adaptive Linear Neuron\\
	\end{center}
	\normalsize
	Dataset:
	\begin{enumerate}
		\item $\left\{x_1=\begin{bmatrix}
			-1 \\ 2
		\end{bmatrix}, t_1=1\right\}$
		\item $\left\{x_2=\begin{bmatrix}
			0 \\ 2
		\end{bmatrix}, t_2=1\right\}$
		\item $\left\{x_3=\begin{bmatrix}
			3 \\ -2
		\end{bmatrix}, t_3=1\right\}$
		\item $\left\{x_4=\begin{bmatrix}
			-2 \\ -1
		\end{bmatrix}, t_4=-1\right\}$
		\item $\left\{x_5=\begin{bmatrix}
			0 \\ -3
		\end{bmatrix}, t_5=-1\right\}$
	\end{enumerate}
	Initial Weight and Bias: \\
	w = $\begin{bmatrix}
		3.0 & 1.0
	\end{bmatrix}$ \\
	b = 1.0 \\
	$\alpha$ = 0.05 \\
	\begin{center}
		\includegraphics[width=0.7\textwidth]{initial_plot.png} \\
		\Large Algorithm
	\end{center}
	for each iteration, 
	\\ 1. calculate output:
	\begin{align*}
		a_j & = \sum w_{ij} p + b,~\text{where}\\
		a_j & = \text{Output}, w = \text{Weight}, p = \text{Input},~\text{and}~b = \text{Bias}
	\end{align*}
	\\ 2. compute loss function / error:
	\begin{align*}
		E(k) & = (t_k - a_k)^2,~\text{where} \\
		E(k) & = \text{Least Square Error}~, \\
		t_k & = \text{Desired target input}, \\
		a_k & = \text{Output}
	\end{align*}
	\\ 3. Update weights:
	\begin{align*}
		w_{new} & = w_{old} + \Delta w, ~\text{where} \\
		w_{new} & = \text{updated weight}\\
		w_{old} & = \text{initial weight} \\
		\Delta w & = 2 \alpha (t - a) p
	\end{align*}
	\\ 4. Update bias:
	\begin{align*}
		b_{new} & = b_{old} + \Delta b,~ \text{where} \\
		b_{new} & = \text{updated bias} \\
		b_{old} & = \text{initial bias} \\
		\Delta b & = 2 \alpha (t - a)
	\end{align*}
	\\ 5. Repeat until error is sufficiently low / zero
	\begin{center}
		\Large Training \\
	\end{center}
	Epoch 1 \\
	1-th Iteration: \\
	Calculate output: 
	\begin{equation}
		\begin{split}
			a_1 & = w.x+b \\
			& = \begin{bmatrix}
				3.0 & 1.0
			\end{bmatrix}. \begin{bmatrix}
				-1 \\ 2
			\end{bmatrix} + 1 \\
			a_1 & = 0
		\end{split}
	\end{equation}
	Calculate error: 
	\begin{equation}
		\begin{split}
			E & = (t - a)^2 \\
			E & = (1 - 0)^2 \\
			E & = 1.0
		\end{split}
	\end{equation}
	Update weights:
	\begin{equation}
		\begin{split}
			w_{new} & = w_{old} + 2 \alpha e p^T \\
			w_{new} & = \begin{bmatrix}
				3 & 1
			\end{bmatrix} + (2)(0.05)(1.0) (\begin{bmatrix}
			-1 & 2
		\end{bmatrix}) \\
			w_{new} & = \begin{bmatrix}
				3 & 1
			\end{bmatrix} + \begin{bmatrix}
			-0.1 & 0.2
		\end{bmatrix} \\
			w_{new} & = \begin{bmatrix}
				2.9 & 1.2
			\end{bmatrix}
		\end{split}
	\end{equation}
	Update bias:
	\begin{equation}
		\begin{split}
			b_{new} & = b_{old} + 2 \alpha e \\
			b_{new} & = 1.0 + (2)(0.05)(1) \\
			b_{new} & = 1.0 + 0.1 \\
			b_{new} & = 1.1 \\
		\end{split}
	\end{equation}
	2-nd Iteration: \\
	Calculate output: 
	\begin{equation}
		\begin{split}
			a_1 & = w.x+b \\
			& = \begin{bmatrix}
				2.9 & 1.2
			\end{bmatrix}. \begin{bmatrix}
				0 \\ 2
			\end{bmatrix} + 1.1 \\
			a_1 & = 3.5
		\end{split}
	\end{equation}
	Calculate error: 
	\begin{equation}
		\begin{split}
			E & = (t - a)^2 \\
			E & = (1 - 3.5)^2 \\
			E & = 6.25
		\end{split}
	\end{equation}
	Update weights:
	\begin{equation}
		\begin{split}
			w_{new} & = w_{old} + 2 \alpha e p^T \\
			w_{new} & = \begin{bmatrix}
				2.9 & 1.2
			\end{bmatrix} + (2)(0.05)(-2.5) (\begin{bmatrix}
				0 & 2
			\end{bmatrix} ) \\
			w_{new} & = \begin{bmatrix}
				2.9 & 1.2
			\end{bmatrix} + \begin{bmatrix}
				0 & -0.5
			\end{bmatrix} \\
			w_{new} & = \begin{bmatrix}
				2.9 & 0.7
			\end{bmatrix}
		\end{split}
	\end{equation}
	Update bias:
	\begin{equation}
		\begin{split}
			b_{new} & = b_{old} + 2 \alpha e \\
			b_{new} & = 1.1 + (2)(0.05)(-2.5) \\
			b_{new} & = 1.1 + -0.25 \\
			b_{new} & = 0.85 \\
		\end{split}
	\end{equation}
	3-rd Iteration: \\
	Calculate output: 
	\begin{equation}
		\begin{split}
			a_1 & = w.x+b \\
			& = \begin{bmatrix}
				2.9 & 0.7
			\end{bmatrix}. \begin{bmatrix}
				3 \\ -2
			\end{bmatrix} + 0.85 \\
			a_1 & = 3.5
		\end{split}
	\end{equation}
	Calculate error: 
	\begin{equation}
		\begin{split}
			E & = (t - a)^2 \\
			E & = (1 - 3.5)^2 \\
			E & = 6.25
		\end{split}
	\end{equation}
	Update weights:
	\begin{equation}
		\begin{split}
			w_{new} & = w_{old} + 2 \alpha e p^T \\
			w_{new} & = \begin{bmatrix}
				2.9 & 1.2
			\end{bmatrix} + (2)(0.05)(-2.5) (\begin{bmatrix}
				0 & 2
			\end{bmatrix} ) \\
			w_{new} & = \begin{bmatrix}
				2.9 & 1.2
			\end{bmatrix} + \begin{bmatrix}
				0 & -0.5
			\end{bmatrix} \\
			w_{new} & = \begin{bmatrix}
				2.9 & 0.7
			\end{bmatrix}
		\end{split}
	\end{equation}
	Update bias:
	\begin{equation}
		\begin{split}
			b_{new} & = b_{old} + 2 \alpha e \\
			b_{new} & = 1.1 + (2)(0.05)(-2.5) \\
			b_{new} & = 1.1 + -0.25 \\
			b_{new} & = 0.85 \\
		\end{split}
	\end{equation}
\end{document}